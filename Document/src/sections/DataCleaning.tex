

Data cleansing is the process of detecting and correcting (or removing) corrupt or inaccurate records from a database \cite{datacleansing}.
It is one of the principal tasks of data science, as the use of inconsistent data can lead to false conclusions.\\


While the characterization of the API was being performed, strange values were detected in the data, such as distances and remaining times that were too large, or even negative. In order to eliminate these contaminated values and thus improve the quality of the models to be built in the future, we have tested if the data meets a series of criteria established with our a-priori knowledge, eliminating the rows that did not meet them. 


\subsection{Consistency criteria}

The coherence and consistency rules set for the data are: 

\begin{enumerate}
    \item \textbf{Consistency between line, destination and stop: }Checks if the stop that has given the data really belongs to the line and destination specified in the row.
    \item \textbf{Positive distances remaining to the stops: }Checks if the remaining distances from the buses to the stops are greater than zero.
    \item \textbf{Remaining distances to the stops lower than the line length: }Checks if the remaining distances from the buses to the stops are lower than the total length of the line to which they belong.
    \item \textbf{Positive remaining times to reach the stops: }Checks if the remaining times of the buses to the stops are greater than zero.
    \item \textbf{Remaining time less than two hours: }Checks if the remaining times of the buses to the stops are less than two hours.
    \item \textbf{Remaining times too high in relation to line length: }If the time remaining of the bus to the stop is greater than that which would be necessary to go through the entire line at 7.2km/h, the value is considered an outlier.
    \item \textbf{Estimated speed too high or negative: }Checks that the speed resulting from dividing the remaining distance by the remaining time to the stop is positive and less than 120 km/h. 
\end{enumerate}

\subsection{Results}

Applying all these criteria on our data through the script ``preprocess\textunderscore clean\textunderscore data.py'', we are left with approximately $95\%$ of the original data, so $5\%$ of the rows are considered as outliers or defective.

\begin{figure}[H]
\centering
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{../images/outlier1.png}
  \caption{Remaining time unusually high.}
  \label{fig:outlier1}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{../images/outlier2.png}
  \caption{Distance remaining lower than zero.}
  \label{fig:outlier2}
\end{subfigure}
\caption{Example of two rows which would be considered as outliers or defective and eliminated from the training data.}
\label{fig:outliersfound}
\end{figure}